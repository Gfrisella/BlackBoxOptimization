{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import botorch\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda')\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerClass():\n",
    "    '''Mother class for optimizers'''\n",
    "    def __init__(self,true_model,\n",
    "                 surrogate_model,\n",
    "                 bounds:tuple,\n",
    "                 initial_phi:torch.tensor = None,\n",
    "                 device = torch.device('cuda'),\n",
    "                 history:tuple = (),\n",
    "                 WandB:dict = {'name': 'Optimization'},\n",
    "                 outputs_dir = 'outputs',\n",
    "                 resume:bool = False):\n",
    "        \n",
    "        self.device = device\n",
    "        self.true_model = true_model\n",
    "        #self.model = self.surrogate_model_class(*self.history).to(self.device)\n",
    "        self._i = len(self.history[0]) if resume else 0\n",
    "        print('STARTING FROM i = ', self._i)\n",
    "        self.model = surrogate_model\n",
    "        self.bounds = bounds.cpu()\n",
    "        self.wandb = WandB\n",
    "        self.outputs_dir = outputs_dir\n",
    "\n",
    "    def fit_surrogate_model(self,**kwargs):\n",
    "        D = self.clean_training_data() #Should we do this here, in every iteration?\n",
    "        self.model = self.model.fit(D[0].to(self.device),D[1].to(self.device),**kwargs)\n",
    "    def update_history(self,phi,y):\n",
    "        '''Append phi and y to D'''\n",
    "        phi,y = phi.reshape(-1,self.history[0].shape[1]).cpu(), y.reshape(-1,self.history[1].shape[1]).cpu()\n",
    "        self.history = (torch.cat([self.history[0], phi]),torch.cat([self.history[1], y]))\n",
    "    def n_iterations(self):\n",
    "        return self._i\n",
    "    def stopping_criterion(self,**convergence_params):\n",
    "        return self._i >= convergence_params['max_iter']\n",
    "    def get_optimal(self):\n",
    "        '''Get the current optimal'''\n",
    "        idx = self.history[1].argmin()\n",
    "        return self.history[0][idx],self.history[1][idx]\n",
    "    def clean_training_data(self):\n",
    "        '''Get samples on history for training'''\n",
    "        return self.history\n",
    "    \n",
    "class BayesianOptimizer(OptimizerClass):\n",
    "    \n",
    "    def __init__(self,true_model,\n",
    "                 surrogate_model,\n",
    "                 bounds:tuple,\n",
    "                 initial_phi:torch.tensor = None,\n",
    "                 device = torch.device('cuda'),\n",
    "                 acquisition_fn = botorch.acquisition.ExpectedImprovement,\n",
    "                 acquisition_params = {'num_restarts': 30, 'raw_samples':5000},\n",
    "                 history:tuple = (),\n",
    "                 model_scheduler:dict = {},\n",
    "                 WandB:dict = {'name': 'BayesianOptimization'},\n",
    "                 reduce_bounds:int = 4000,\n",
    "                 outputs_dir = 'outputs',\n",
    "                 resume:bool = False):\n",
    "        super().__init__(true_model,\n",
    "                 surrogate_model,\n",
    "                 bounds,\n",
    "                 initial_phi=initial_phi,\n",
    "                 device = device,\n",
    "                 history = history,\n",
    "                 WandB = WandB,\n",
    "                 outputs_dir = outputs_dir,\n",
    "                 resume = resume)\n",
    "        \n",
    "        self.acquisition_fn = acquisition_fn\n",
    "        self.acquisition_params = acquisition_params\n",
    "        self.model_scheduler = model_scheduler\n",
    "        self._iter_reduce_bounds = reduce_bounds\n",
    "        if resume: #current model from model_scheduler\n",
    "            for i in model_scheduler:\n",
    "                if self._i > i:\n",
    "                    self.model = model_scheduler[i]\n",
    "        \n",
    "    def get_new_phi(self):\n",
    "        '''Minimize acquisition function, returning the next phi to evaluate'''\n",
    "        acquisition = self.acquisition_fn(self.model, self.history[1].min().to(self.device), maximize=False)\n",
    "        return botorch.optim.optimize.optimize_acqf(acquisition, self.bounds.to(self.device), q=1,**self.acquisition_params)[0]\n",
    "    def run_optimization(self, \n",
    "                         use_scipy:bool = True,\n",
    "                         save_optimal_phi:bool = True,\n",
    "                         save_history:bool = False,\n",
    "                         **convergence_params):\n",
    "\n",
    "        options = {'lr': 1e-2, 'maxiter': 100} if not use_scipy else None\n",
    "        while not self.stopping_criterion(**convergence_params):\n",
    "            if self._i in self.model_scheduler:\n",
    "                self.model = self.model_scheduler[self._i]\n",
    "            if self._i == self._iter_reduce_bounds:\n",
    "                self.reduce_bounds()\n",
    "            self.fit_surrogate_model(use_scipy = use_scipy,options = options)\n",
    "            phi = self.get_new_phi()\n",
    "            y = self.true_model(phi)\n",
    "            self.update_history(phi,y)\n",
    "            self._i += 1\n",
    "        idx = self.history[1].argmin()\n",
    "        return self.history[0][idx],self.history[1][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GetBounds(zGap:float = 1.,device = torch.device('cpu')):\n",
    "        magnet_lengths = [(170 + zGap, 300 + zGap)] * 6  \n",
    "        dX_bounds = [(10, 100)] * 2\n",
    "        dY_bounds = [(20, 200)] * 2 \n",
    "        gap_bounds = [(2, 70)] * 2 \n",
    "        bounds = magnet_lengths + 6*(dX_bounds + dY_bounds + gap_bounds)\n",
    "        bounds = torch.tensor(bounds,device=device,dtype=torch.get_default_dtype()).T\n",
    "        return bounds\n",
    "\n",
    "def standardize(y:torch.tensor):\n",
    "    std = y.std() if y.std()>0 else 1\n",
    "    return (y-y.mean())/std\n",
    "class GP_RBF(botorch.models.SingleTaskGP):\n",
    "    def __init__(self,bounds,device = 'cpu'):\n",
    "        self.device = device\n",
    "        self.bounds = bounds\n",
    "    def fit(self,X,Y,use_scipy = True,options:dict = None,**kwargs):\n",
    "        #self.train()\n",
    "        Y = standardize(Y)\n",
    "        X = self.normalization(X,self.bounds)\n",
    "        super().__init__(X,Y,**kwargs)\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self)\n",
    "        if use_scipy:\n",
    "            botorch.fit.fit_gpytorch_mll(mll)\n",
    "        else:\n",
    "            botorch.fit.fit_gpytorch_mll(mll,optimizer=botorch.optim.fit.fit_gpytorch_mll_torch, options=options)\n",
    "        return self\n",
    "    def forward(self,x):\n",
    "        x = self.normalization(x, bounds=self.bounds)\n",
    "        return super().forward(x)\n",
    "    @staticmethod\n",
    "    def normalization(X, bounds):\n",
    "        return (X - bounds[0,:]) / (bounds[1,:] - bounds[0,:])\n",
    "    def predict(self,x,return_std = False,**kwargs):\n",
    "        #self.eval()\n",
    "        x = self.normalization(x,self.bounds)\n",
    "        observed_pred = self.posterior(x,**kwargs)\n",
    "        y_pred = observed_pred.mean.cpu()\n",
    "        std_pred = observed_pred.mvn.covariance_matrix.diag().sqrt().cpu()\n",
    "        if return_std: return y_pred,std_pred\n",
    "        else: return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def olivers_fn(phi:torch.tensor,x = None,w:float = 5,gamma:float = 1,noise = False):\n",
    "    y = torch.prod(torch.sin(w*phi)*(1-torch.tanh(gamma*phi.pow(2))),-1,keepdims=True)\n",
    "    if noise:\n",
    "        y += torch.randn_like(y)*noise\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import   load\n",
    "from os.path import join\n",
    "from gzip import open as gzip_open\n",
    "with gzip_open(join('/home/hep/lprate/projects/BlackBoxOptimization/outputs/complete_57_SC','history.pkl')) as f:\n",
    "    X,Y = load(f)\n",
    "    X = X[:1000].to(torch.get_default_dtype())\n",
    "    Y = Y[:1000].to(torch.get_default_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = GetBounds().to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GP_RBF(bounds,dev)\n",
    "acquisition_fn = botorch.acquisition.qLogExpectedImprovement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X.to(dev),Y.to(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition = acquisition_fn(model, Y.min().to(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botorch.optim.optimize.optimize_acqf(acquisition, bounds.to(dev), q=5,**{'num_restarts': 30, 'raw_samples':5000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
