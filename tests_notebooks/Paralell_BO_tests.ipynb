{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import botorch\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerClass():\n",
    "    '''Mother class for optimizers'''\n",
    "    def __init__(self,true_model,\n",
    "                 surrogate_model,\n",
    "                 bounds:tuple,\n",
    "                 initial_phi:torch.tensor = None,\n",
    "                 device = torch.device('cuda'),\n",
    "                 history:tuple = (),\n",
    "                 WandB:dict = {'name': 'Optimization'},\n",
    "                 outputs_dir = 'outputs',\n",
    "                 resume:bool = False):\n",
    "        \n",
    "        self.device = device\n",
    "        self.true_model = true_model\n",
    "        #self.model = self.surrogate_model_class(*self.history).to(self.device)\n",
    "        self._i = len(self.history[0]) if resume else 0\n",
    "        print('STARTING FROM i = ', self._i)\n",
    "        self.model = surrogate_model\n",
    "        self.bounds = bounds.cpu()\n",
    "        self.wandb = WandB\n",
    "        self.outputs_dir = outputs_dir\n",
    "\n",
    "    def fit_surrogate_model(self,**kwargs):\n",
    "        D = self.clean_training_data() #Should we do this here, in every iteration?\n",
    "        self.model = self.model.fit(D[0].to(self.device),D[1].to(self.device),**kwargs)\n",
    "    def update_history(self,phi,y):\n",
    "        '''Append phi and y to D'''\n",
    "        phi,y = phi.reshape(-1,self.history[0].shape[1]).cpu(), y.reshape(-1,self.history[1].shape[1]).cpu()\n",
    "        self.history = (torch.cat([self.history[0], phi]),torch.cat([self.history[1], y]))\n",
    "    def n_iterations(self):\n",
    "        return self._i\n",
    "    def stopping_criterion(self,**convergence_params):\n",
    "        return self._i >= convergence_params['max_iter']\n",
    "    def get_optimal(self):\n",
    "        '''Get the current optimal'''\n",
    "        idx = self.history[1].argmin()\n",
    "        return self.history[0][idx],self.history[1][idx]\n",
    "    def clean_training_data(self):\n",
    "        '''Get samples on history for training'''\n",
    "        return self.history\n",
    "    \n",
    "class BayesianOptimizer(OptimizerClass):\n",
    "    \n",
    "    def __init__(self,true_model,\n",
    "                 surrogate_model,\n",
    "                 bounds:tuple,\n",
    "                 initial_phi:torch.tensor = None,\n",
    "                 device = torch.device('cuda'),\n",
    "                 acquisition_fn = botorch.acquisition.ExpectedImprovement,\n",
    "                 acquisition_params = {'num_restarts': 30, 'raw_samples':5000},\n",
    "                 history:tuple = (),\n",
    "                 model_scheduler:dict = {},\n",
    "                 WandB:dict = {'name': 'BayesianOptimization'},\n",
    "                 reduce_bounds:int = 4000,\n",
    "                 outputs_dir = 'outputs',\n",
    "                 resume:bool = False):\n",
    "        super().__init__(true_model,\n",
    "                 surrogate_model,\n",
    "                 bounds,\n",
    "                 initial_phi=initial_phi,\n",
    "                 device = device,\n",
    "                 history = history,\n",
    "                 WandB = WandB,\n",
    "                 outputs_dir = outputs_dir,\n",
    "                 resume = resume)\n",
    "        \n",
    "        self.acquisition_fn = acquisition_fn\n",
    "        self.acquisition_params = acquisition_params\n",
    "        self.model_scheduler = model_scheduler\n",
    "        self._iter_reduce_bounds = reduce_bounds\n",
    "        if resume: #current model from model_scheduler\n",
    "            for i in model_scheduler:\n",
    "                if self._i > i:\n",
    "                    self.model = model_scheduler[i]\n",
    "        \n",
    "    def get_new_phi(self):\n",
    "        '''Minimize acquisition function, returning the next phi to evaluate'''\n",
    "        acquisition = self.acquisition_fn(self.model, self.history[1].min().to(self.device), maximize=False)\n",
    "        return botorch.optim.optimize.optimize_acqf(acquisition, self.bounds.to(self.device), q=1,**self.acquisition_params)[0]\n",
    "    def run_optimization(self, \n",
    "                         use_scipy:bool = True,\n",
    "                         save_optimal_phi:bool = True,\n",
    "                         save_history:bool = False,\n",
    "                         **convergence_params):\n",
    "\n",
    "        options = {'lr': 1e-2, 'maxiter': 100} if not use_scipy else None\n",
    "        while not self.stopping_criterion(**convergence_params):\n",
    "            if self._i in self.model_scheduler:\n",
    "                self.model = self.model_scheduler[self._i]\n",
    "            if self._i == self._iter_reduce_bounds:\n",
    "                self.reduce_bounds()\n",
    "            self.fit_surrogate_model(use_scipy = use_scipy,options = options)\n",
    "            phi = self.get_new_phi()\n",
    "            y = self.true_model(phi)\n",
    "            self.update_history(phi,y)\n",
    "            self._i += 1\n",
    "        idx = self.history[1].argmin()\n",
    "        return self.history[0][idx],self.history[1][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def olivers_fn(phi:torch.tensor,x = None,w:float = 5,gamma:float = 1,noise = False):\n",
    "    y = torch.prod(torch.sin(w*phi)*(1-torch.tanh(gamma*phi.pow(2))),-1,keepdims=True)\n",
    "    if noise:\n",
    "        y += torch.randn_like(y)*noise\n",
    "    return y\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
